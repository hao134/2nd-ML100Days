{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 96
    },
    "colab_type": "code",
    "id": "N6UNvU9QxxHd",
    "outputId": "1fd13cc0-1386-4ea6-c7b4-5850dd0ca96f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "colab_type": "code",
    "id": "o-TUz7VKx8K-",
    "outputId": "abf68b2a-0a68-4e78-9dc7-cbf602e5a84c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug  2 05:23:05 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   55C    P8    16W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "nDi1hky0xxHr",
    "outputId": "7fd79e2d-c494-42e1-d641-f1527ec27f16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 2s 0us/step\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128 # batch 的大小，如果出現 OOM error，請降低這個值\n",
    "num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n",
    "epochs = 10 # 訓練的 epochs 數量\n",
    "\n",
    "# 讀取資料並檢視\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# 對 label 進行 one-hot encoding (y_trian 原本是純數字)\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GGm8H3oMxxH1"
   },
   "source": [
    "## 首先我們使用一般的 DNN (MLP) 來訓練\n",
    "由於 DNN 只能輸入一維的資料，我們要先將影像進行攤平，若 (50000, 32, 32, 3) 的影像，攤平後會變成 (50000, 32*32*3) = (50000, 3072)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "colab_type": "code",
    "id": "R-l5_594xxH6",
    "outputId": "ce7098fc-4956-4de9-ff98-7c405ebe4ac0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# 將資料攤平成一維資料\n",
    "x_train = x_train.reshape(50000, 3072) \n",
    "x_test = x_test.reshape(10000, 3072)\n",
    "\n",
    "# 將資料變為 float32 並標準化\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Eli6v6yNxxII",
    "outputId": "a119f064-a163-4959-c01d-0a09374d5614"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0802 05:24:57.801689 139841364395904 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0802 05:24:57.841480 139841364395904 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0802 05:24:57.847469 139841364395904 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0802 05:24:57.864069 139841364395904 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0802 05:24:57.872581 139841364395904 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0802 05:24:57.941334 139841364395904 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0802 05:24:57.952916 139841364395904 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0802 05:24:58.064837 139841364395904 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,841,162\n",
      "Trainable params: 1,841,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 2.1683 - acc: 0.2529 - val_loss: 1.9458 - val_acc: 0.3092\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.8603 - acc: 0.3290 - val_loss: 1.7223 - val_acc: 0.3954\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.7854 - acc: 0.3603 - val_loss: 1.7850 - val_acc: 0.3555\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.7304 - acc: 0.3799 - val_loss: 1.6785 - val_acc: 0.3859\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.6923 - acc: 0.3924 - val_loss: 1.5988 - val_acc: 0.4291\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.6691 - acc: 0.4035 - val_loss: 1.6520 - val_acc: 0.4059\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.6497 - acc: 0.4106 - val_loss: 1.6143 - val_acc: 0.4257\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 1.6241 - acc: 0.4174 - val_loss: 1.6475 - val_acc: 0.4184\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.6136 - acc: 0.4222 - val_loss: 1.5851 - val_acc: 0.4342\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 1.5999 - acc: 0.4266 - val_loss: 1.5683 - val_acc: 0.4396\n",
      "Test loss: 1.5682614181518555\n",
      "Test accuracy: 0.4396\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(3072,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aSzFvhtZxxIN"
   },
   "source": [
    "## 接下來我們使用 CNN 來訓練神經網路\n",
    "CNN 的原理非常適合處理影像類的資料，就讓我們來看看，同樣的訓練條件，CNN 是否顯著優於 DNN 呢?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "id": "m83ZvvdixxIP",
    "outputId": "11cf94fe-4fd3-4f63-e443-9db2c1097173"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "m9xjDKQPxxId",
    "outputId": "45aa8a64-97f1-4d2c-d55e-8360978df05f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0802 05:27:30.458852 139841364395904 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 1.7527 - acc: 0.3658 - val_loss: 1.3105 - val_acc: 0.5303\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.3118 - acc: 0.5338 - val_loss: 1.1587 - val_acc: 0.5892\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.1252 - acc: 0.6051 - val_loss: 1.0134 - val_acc: 0.6472\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.9913 - acc: 0.6527 - val_loss: 0.8940 - val_acc: 0.6908\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 0.9019 - acc: 0.6862 - val_loss: 0.9058 - val_acc: 0.6937\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.8293 - acc: 0.7113 - val_loss: 0.7963 - val_acc: 0.7159\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.7723 - acc: 0.7316 - val_loss: 0.8021 - val_acc: 0.7287\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.7364 - acc: 0.7442 - val_loss: 0.7664 - val_acc: 0.7402\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.7002 - acc: 0.7573 - val_loss: 0.6984 - val_acc: 0.7582\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.6730 - acc: 0.7689 - val_loss: 0.6908 - val_acc: 0.7675\n",
      "Test loss: 0.690822065448761\n",
      "Test accuracy: 0.7675\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ADvKjiQBxxIq"
   },
   "source": [
    "## 同樣運算 10 個 epochs，但 CNN 在 test data 的準確率顯著優於 DNN!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uGmdAOqcxxIu"
   },
   "source": [
    "## 作業\n",
    "1. 請試著調整各個超參數，並說明那些超參數對於結果有明顯的影響?\n",
    "2. CNN 與 DNN 哪個模型的參數數量比較多? 造成參數的數量不同的原因在哪?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "CpMQgmTzxxIw",
    "outputId": "e806ca1a-4aa3-4623-fa46-8b9b8294d7e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 1.6058 - acc: 0.4152 - val_loss: 1.2763 - val_acc: 0.5439\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.2057 - acc: 0.5697 - val_loss: 1.0633 - val_acc: 0.6187\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.0429 - acc: 0.6323 - val_loss: 0.9355 - val_acc: 0.6712\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.9325 - acc: 0.6727 - val_loss: 0.8136 - val_acc: 0.7160\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.8541 - acc: 0.6995 - val_loss: 0.8129 - val_acc: 0.7144\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.7846 - acc: 0.7271 - val_loss: 0.7440 - val_acc: 0.7398\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.7310 - acc: 0.7420 - val_loss: 0.7100 - val_acc: 0.7513\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.6966 - acc: 0.7547 - val_loss: 0.6732 - val_acc: 0.7648\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.6551 - acc: 0.7671 - val_loss: 0.6913 - val_acc: 0.7610\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.6194 - acc: 0.7831 - val_loss: 0.6632 - val_acc: 0.7706\n",
      "Test loss: 0.6631879909515381\n",
      "Test accuracy: 0.7706\n"
     ]
    }
   ],
   "source": [
    "# change the optimizer to Adam\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KvHKW4340vt2"
   },
   "source": [
    "### use optimizer Adam is better (slightly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "e614Z3Oz0Z51",
    "outputId": "fa945b68-6e1e-4b29-be0b-c8069b1672f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.5869 - acc: 0.4182 - val_loss: 1.2098 - val_acc: 0.5631\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.1910 - acc: 0.5773 - val_loss: 1.0296 - val_acc: 0.6319\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.0072 - acc: 0.6443 - val_loss: 0.8917 - val_acc: 0.6909\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.8917 - acc: 0.6881 - val_loss: 0.8006 - val_acc: 0.7192\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.8043 - acc: 0.7183 - val_loss: 0.7427 - val_acc: 0.7457\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.7426 - acc: 0.7399 - val_loss: 0.7427 - val_acc: 0.7419\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.6959 - acc: 0.7548 - val_loss: 0.6603 - val_acc: 0.7684\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.6550 - acc: 0.7711 - val_loss: 0.6662 - val_acc: 0.7757\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.6236 - acc: 0.7815 - val_loss: 0.6298 - val_acc: 0.7814\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.5861 - acc: 0.7938 - val_loss: 0.6240 - val_acc: 0.7825\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.5622 - acc: 0.8003 - val_loss: 0.6210 - val_acc: 0.7868\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.5337 - acc: 0.8119 - val_loss: 0.6023 - val_acc: 0.7931\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.5102 - acc: 0.8211 - val_loss: 0.5954 - val_acc: 0.7990\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.4860 - acc: 0.8279 - val_loss: 0.5886 - val_acc: 0.7977\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.4700 - acc: 0.8329 - val_loss: 0.5962 - val_acc: 0.7961\n",
      "Test loss: 0.5962438059806824\n",
      "Test accuracy: 0.7961\n"
     ]
    }
   ],
   "source": [
    "# change epochs 10 to 15, and use Adam optimizer\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs= 15 ,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f4q8XaUD1xQ9"
   },
   "source": [
    "### it is likely to be overfitting at epochs 14, so the better choice of epoch may be 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ipD8H351_nY"
   },
   "source": [
    "### DNN 的參數比較多，因為用cnn會有參數共享的功用，所需參數會比較少。\n",
    "\n",
    "![](https://i.imgur.com/rM8M8Xo.jpg)\n",
    "\n",
    "![](https://i.imgur.com/wQiLEvT.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "btph0ARm1RhJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Day097_Keras_CNN_vs_DNN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
